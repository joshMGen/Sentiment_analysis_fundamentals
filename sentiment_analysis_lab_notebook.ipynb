{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt4all import GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_model = GPT4All(r\"/home/pslearner/LLM_models/mistral-7b-openorca.gguf2.Q4_0-004.gguf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with LLM's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided prompt engineering for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a sentiment analysis AI that returns the sentiment of the sentence given in the format of {sentiment}: {probability of correctness}.'}\n",
      "{'role': 'user', 'content': 'i hate bees'}\n",
      "{'role': 'assistant', 'content': ' {negative}: 0.987654321 ###'}\n"
     ]
    }
   ],
   "source": [
    "with mistral_model.chat_session(system_prompt=r\"\"):\n",
    "    response = mistral_model.generate(prompt= \"\", max_tokens=20, temp=0.1, streaming=False)\n",
    "    for x in mistral_model.current_chat_session:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a sentiment analysis AI that returns the sentiment of the sentence given in the format of {sentiment}: {probability of correctness}. where sentiment can only be positive,negative, or neutral'}\n",
      "{'role': 'user', 'content': 'i absolutely love how cute bees are'}\n",
      "{'role': 'assistant', 'content': '{positive}: 0.98'}\n"
     ]
    }
   ],
   "source": [
    "with mistral_model.chat_session(system_prompt=r\"\"):\n",
    "    response = mistral_model.generate(prompt= \"\", max_tokens=20, temp=0.1, streaming=False)\n",
    "    for x in mistral_model.current_chat_session:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a sentiment analysis AI that returns the sentiment of the sentence given in the format of sentiment: probability of correctness. where sentiment can only be positive,negative, or neutral'}\n",
      "{'role': 'user', 'content': 'tacos are barely better than nothing'}\n",
      "{'role': 'assistant', 'content': ' negative: 0.95'}\n"
     ]
    }
   ],
   "source": [
    "with mistral_model.chat_session(system_prompt=r\"You are a sentiment analysis AI that returns the sentiment of the sentence given in the format of sentiment: probability of correctness. where sentiment can only be positive,negative, or neutral\"):\n",
    "    response = mistral_model.generate(prompt= \"\", max_tokens=20, temp=0.1, streaming=False)\n",
    "    for x in mistral_model.current_chat_session:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Formatting LLM Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a sentiment analysis AI that returns the sentiment of the sentence given in the format of sentiment, sentence, probability of correctness. where sentiment can only be positive,negative, or neutral'}\n",
      "{'role': 'user', 'content': 'tacos are barely better than nothing'}\n",
      "{'role': 'assistant', 'content': ' negative, tacos are barely better than nothing, 0.95'}\n"
     ]
    }
   ],
   "source": [
    "with mistral_model.chat_session(system_prompt=r\"\"):\n",
    "    response = mistral_model.generate(prompt= \"tacos are barely better than nothing\", max_tokens=20, temp=0.1, streaming=False)\n",
    "    for x in mistral_model.current_chat_session:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'You are a sentiment analysis AI that returns the sentiment of the sentence given in the format of sentiment, sentence, probability of correctness. no additional explaination should be written. probability of correctness should be 3 significant figures. where sentiment can only be positive,negative, or neutral'}\n",
      "{'role': 'user', 'content': 'chicken ceaser salads are the best'}\n",
      "{'role': 'assistant', 'content': 'positive, chicken ceaser salads are the best, 0.987'}\n"
     ]
    }
   ],
   "source": [
    "with mistral_model.chat_session(system_prompt=r\"\"):\n",
    "    response = mistral_model.generate(prompt= \"tacos are barely better than nothing\", max_tokens=20, temp=0.1, streaming=False)\n",
    "    for x in mistral_model.current_chat_session:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
